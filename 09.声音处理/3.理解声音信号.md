[《Python应用实战》视频课程](https://study.163.com/course/courseMain.htm?courseId=1209533804&share=2&shareId=400000000624093)

# 理解声音信号

难度：★★★★☆

## 环境准备

- [声音文件](programs/audio/)

|文件名|声道|采样频率|采样格式|时间长度|说明|
|---------|---------|---------|---------|---------|---------|
|example0.wav|2|44100|2字节|约4秒|“是时候表演真正的技术了”|
|example1.wav|1|22050|2字节|约4秒|一段音乐|
|example2.wav|1|22050|2字节|2秒|1047HZ声音|

- 演示所必要的基础库
  + pyaudio
  + pywave
  + [audioop](https://docs.python.org/3/library/audioop.html)
  + numpy
  + scipy
  + pandas
  + matplotlib
  + seaborn

- 头部代码
  ```python
  import pyaudio
  import wave
  import audioop
  import matplotlib.pyplot as plt
  import numpy as np
  import pandas as pd
  import scipy
  import seaborn as sns

  def play(data, sr=44100, sw=2, nchanels=1):
    '''使用缺省设备进行声音播放'''

    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(sw),
                    channels=nchanels,
                    rate=sr,
                    output=True)
    stream.write(data)
    stream.stop_stream()
    stream.close()
    p.terminate()
  ```

## 采样特性转换

  ```python
  def GetMonoData(wavfilename, sr=44100, sw=2):
    '''读wave文件的内容，将数据转化为单声道、采样频率sr、采样宽度sw字节'''

    wf = wave.open(wavfilename, 'rb')
    data = wf.readframes(-1)

    if wf.getnchannels()==2:
      '''当声道为2时，转化成单声道'''
      data = audioop.tomono(data, 2, 0.5, 0.5)
    elif wf.getnchannels()>2:
      return None

    if wf.getsampwidth()!=sw:
      '''将采样格式转化为目标采样格式（缺省2字节）'''
      data = audioop.lin2lin(fragment, wf.getsampwidth(), sw)

    if wf.getframerate() != sr:
      '''将采样频率转化为目标采样频率（缺省44100）'''
      state=None
      data,state=audioop.ratecv(data, sw, 1, wf.getframerate(), sr, state)

    wf.close()
    return data
  ```
  
## PCM数据直接作图

- 所有数据
  ```python
  data = GetMonoData('audio/example0.wav')
  data=np.frombuffer(data,dtype=np.int16)

  plt.figure(figsize=(14, 5))
  plt.plot(data)
  plt.show()
  ```

- 局部数据
  ```python
  data = GetMonoData('audio/example0.wav')
  data=np.frombuffer(data,dtype=np.int16)

  plt.figure(figsize=(14, 5))
  plt.plot(np.arange(50000,50300), data[50000:50300])

  plt.show()
  ```

## 合并两段声音
  ```python
  data1 = GetMonoData('audio/example0.wav')
  data2 = GetMonoData('audio/example1.wav')

  data = audioop.add(data1[0:len(data2)],data2[0:len(data1)],2)
  play(data)
  ```

## 声音能量（声响）
  ```python
  data = GetMonoData('audio/example0.wav')

  times = []
  energys = []
  for i in range(0, len(data)-2048, 2048):
      energy = audioop.rms(data[i:i+2048],2)
      energys.append(energy)
      times.append(i/2/44100)

  plt.figure(figsize=(14, 5))
  plt.plot(times, energys)
  plt.show()
  ```

## 频率

```python
data = GetMonoData('audio/example0.wav')
data=np.frombuffer(data,dtype=np.int16)

interval = 1024

fre = pd.DataFrame()
fre_index = np.linspace(0, 44100, interval, dtype=int)
for i in range(0, len(data)-interval, interval):
    X = scipy.fft(data[i:i+interval])
    X_mag = np.absolute(X)
    s = pd.Series(X_mag[0:200], index=fre_index[0:200])
    fre['%.1f'%(i/44100)] = s

plt.figure(figsize=(14, 5))
sns.heatmap(fre)
plt.show()
```
