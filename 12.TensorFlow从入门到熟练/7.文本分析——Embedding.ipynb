{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zhujisheng/learn_python/blob/master/12.TensorFlow从入门到熟练/7.文本分析——Embedding.ipynb)\n",
    "\n",
    "[《Python应用实战》视频课程](https://study.163.com/course/courseMain.htm?courseId=1209533804&share=2&shareId=400000000624093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分析——Embedding\n",
    "\n",
    "难度：★★★★☆\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是embedding\n",
    "\n",
    "*word embedding将单词转化为向量*\n",
    "\n",
    "![word_embedding](images/word_embedding.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- embedding不会丢失单词在文本中的位置（次序）信息\n",
    "\n",
    "- 向量能蕴含更丰富的信息：\n",
    "\n",
    "    - 类似含义的单词表达为相近的向量\n",
    "\n",
    "    - 单词之间的关系可以表达为向量之差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络中两种embedding处理方式\n",
    "\n",
    "- 使用现成的embedding表，在表中查找文本中每个单词对应的向量表达，将文本进行embedding转换\n",
    "- 在神经网络中训练embedding方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "imdb = keras.datasets.imdb\n",
    "vocab_size = 10000\n",
    "\n",
    "(train_sequences, train_labels), (test_sequences, test_labels) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_sequences_padded = pad_sequences(train_sequences,\n",
    "                                       padding='post',\n",
    "                                       truncating='post',\n",
    "                                       maxlen=256)\n",
    "test_sequences_padded = pad_sequences(test_sequences,\n",
    "                                      padding='post',\n",
    "                                      truncating='post',\n",
    "                                      maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16, input_length=256))\n",
    "#model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding\n",
    "\n",
    "  input_dim: 单词表单词数量\n",
    "  \n",
    "  output_dim: 单词转化为的向量的维度（数组的长度）\n",
    "  \n",
    "  input_length: 每段文本中包含的单词数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_sequences_padded,\n",
    "          train_labels,\n",
    "          epochs=6,\n",
    "          batch_size=512,\n",
    "          validation_data=(test_sequences_padded, test_labels),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text卷积与池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16, input_length=256))\n",
    "#model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Conv1D(16, 3, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "#model.add(keras.layers.Conv1D(16, 3, activation='relu'))\n",
    "#model.add(keras.layers.MaxPooling1D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_sequences_padded,\n",
    "          train_labels,\n",
    "          epochs=6,\n",
    "          batch_size=512,\n",
    "          validation_data=(test_sequences_padded, test_labels),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
