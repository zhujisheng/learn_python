{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zhujisheng/learn_python/blob/master/12.TensorFlow从入门到熟练/5.文本分析——tokenization.ipynb)\n",
    "\n",
    "[《Python应用实战》视频课程](https://study.163.com/course/courseMain.htm?courseId=1209533804&share=2&shareId=400000000624093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分析——tokenization预处理\n",
    "\n",
    "难度：★★★★☆\n",
    "\n",
    "*文本在输入神经网络之前，需要进行预处理——将文本转化为数字表达；这个预处理过程，就称为tokenization。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词汇表\n",
    "\n",
    "- 一般分析文本会以词（word）为单位，不是以字（字母）为单位\n",
    "\n",
    "- 文本要转化为数字表达之前，首先需要建立词汇表\n",
    "\n",
    "- 词汇表中的内容是“词-数字”的对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat very much!'\n",
    "]\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10, oov_token='xxxx')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oov_token\n",
    "\n",
    "oov：out of vocabulate\n",
    "\n",
    "当将文本转化为序列码时，文本中出现了超出词汇表的内容，就以oov_token替代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.texts_to_sequences(['you love your dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 截断与补齐\n",
    "\n",
    "截断与补齐的作用是让文本具有相同的长度，便于作为神经网络的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences_padded = pad_sequences(sequences, maxlen=5, padding='post', truncating='post')\n",
    "print(sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = tokenizer.texts_to_matrix(sentences, mode='binary')\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在one-hot码中，会丢失文本中词汇的次序\n",
    "\n",
    "tokenizer.texts_to_matrix([\"love my dog i\"], mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样例：影评信息的正负面判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载影评序列码数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_sequences, train_labels), (test_sequences, test_labels) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"训练集数据量: \", len(train_sequences))\n",
    "print(\"验证集数据量: \", len(test_sequences))\n",
    "print(\"训练集第一条数据: \", train_sequences[0])\n",
    "print(\"训练集第一条数据的标记: \", train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将序列码转回文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb的词汇表\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "#word_index[\"<PAD>\"] = 0\n",
    "#word_index[\"<START>\"] = 1\n",
    "#word_index[\"<UNK>\"] = 2  # unknown\n",
    "#word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(sequences):\n",
    "    ret = []\n",
    "    for seq in sequences:\n",
    "        ret.append(' '.join([reverse_word_index.get(i,'') for i in seq]).strip())\n",
    "    return ret\n",
    "\n",
    "train_text = np.array(decode_review(train_sequences))\n",
    "test_text = np.array(decode_review(test_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务\n",
    "\n",
    "构建与训练一个神经网络，用于判断影评是正面的（表扬）还是负面的（批评）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
